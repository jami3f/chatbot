{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "from TTS.api import TTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "import re\n",
    "import threading\n",
    "import inflect\n",
    "\n",
    "tts = TTS(\"tts_models/en/jenny/jenny\")\n",
    "model_name = \"tiiuae/falcon-7b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, device_map=\"auto\", pad_token_id=0, load_in_8bit=True\n",
    ")\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    pad_token_id=0,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"You are a helpful chatbot designed to answer any questions you are given as accurately as possible, using facts when possible. Answer the following question: \"\n",
    "prompt = \"please tell me a fact about nature\"\n",
    "\n",
    "# run the model to generate a response\n",
    "sequences = pipeline(\n",
    "    text_inputs=prefix + prompt,\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "# retrieve the generated response\n",
    "response: str = sequences[0][\"generated_text\"].split(\"\\n\")[1].strip()\n",
    "\n",
    "print(response)\n",
    "\n",
    "# remove commas between numbers and convert them to words using the inflect library\n",
    "response = re.sub(r\"(?<=\\d),(?=\\d)\", \"\", response)\n",
    "response = re.sub(r\"\\d+\", lambda x: inflect.engine().number_to_words(x.group()), response)\n",
    "\n",
    "response = \"A fact about nature is that the Northern Lights, also known as auroral displays, are created when solar winds from outer space enter the earth's magnetic field and collide with the nitrogen and oxygen atoms in the atmosphere, causing them to release energy in the form of light. These mesmerising displays can be seen in the night sky and places with clear skies, usuallly during the winter months.\"\n",
    "\n",
    "# split response on punctuation\n",
    "response_split = re.split(r\"!|\\.|,|:|;|\\?\", response)\n",
    "\n",
    "# find the next file number to use (e.g. output0036.wav)\n",
    "current_files = os.listdir(\"chatbot-output\")\n",
    "num = max([int(file.split(\".\")[0].replace(\"output\", \"\")) for file in current_files]) + 1\n",
    "files_to_play = []\n",
    "\n",
    "tts.tts_to_file(\"hi\", file_path=\"./test-output.wav\")\n",
    "\n",
    "# define function to be used by threads later\n",
    "def create_tts_audio(section, file_path):\n",
    "    tts.tts_to_file(text=section, file_path=file_path)\n",
    "    \n",
    "threads = []\n",
    "    \n",
    "for section in response_split:\n",
    "    # filter out empty sections\n",
    "    if section.strip() == \"\":\n",
    "        continue\n",
    "    \n",
    "    # create a thread for each section so they can all be processed in parallel\n",
    "    file_path = f\"chatbot-output/output{num:0>4}.wav\"\n",
    "    files_to_play.append(file_path)\n",
    "    num += 1\n",
    "    thread = threading.Thread(target=create_tts_audio, args=(section, file_path), daemon=True)\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# wait for all threads to finish\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# play all the audio files\n",
    "for file in files_to_play:\n",
    "    playsound(file)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
